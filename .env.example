 USE_SQLITE=False

DB_NAME=postgres
DB_USER=postgres.nwdzqvxtrgahhexgmeca
DB_PASSWORD=RZ.3cw@H45+ZLr*
DB_HOST=aws-1-eu-north-1.pooler.supabase.com
DB_PORT=6543
DB_SSLMODE=require
SECRET_KEY=_7dohk65%2dz$_t412*_^=u2b876+6(m0d-%3=$q)b_bqd_!mn
USE_SQLITE=False

# Fireworks embeddings
EMBEDDING_PROVIDER=fireworks
FIREWORKS_API_KEY=fw_3ZPaFUzNMHy7FLpefcG5QJmS
FIREWORKS_EMBEDDING_MODEL=nomic-ai/nomic-embed-text-v1.5
FIREWORKS_EMBEDDING_DIM=1536
 ELEVENLABS_API_KEY=sk_a2403599f54e51d4a8c89fbaa1f2dff06ae84c9e407b14de


# source venv/bin/activate && export USE_SQLITE=False && export EMBEDDING_PROVIDER=fireworks && export FIREWORKS_API_KEY=fw_3ZPaFUzNMHy7FLpefcG5QJmS && export FIREWORKS_EMBEDDING_MODEL=nomic-ai/nomic-embed-text-v1.5 && export FIREWORKS_EMBEDDING_DIM=768 && echo "Server starting with 768-dimensional embeddings..." && python manage.py runserver 0.0.0.0:8000




# I updated CV upload to embed the parsed text and store vectors in cv_embeddings (pgvector), mirroring job embedding logic.
# What it does now
# After creating the CV row, it chunks the text, embeds each chunk, and inserts rows into cv_embeddings (id, cv_id, created_at, embedding) using the configured embedding provider/dimension. Any per-chunk issues are returned in embedding_warnings.OPENAI_API_KEY=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
OPENAI_API_KEY=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