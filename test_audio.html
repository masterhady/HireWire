<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Audio Interview Test</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            max-width: 800px;
            margin: 50px auto;
            padding: 20px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
        }
        
        .container {
            background: white;
            padding: 30px;
            border-radius: 15px;
            box-shadow: 0 10px 40px rgba(0,0,0,0.2);
        }
        
        h1 {
            color: #333;
            margin-bottom: 30px;
            text-align: center;
        }
        
        .section {
            margin-bottom: 30px;
            padding: 20px;
            background: #f8f9fa;
            border-radius: 10px;
            border-left: 4px solid #667eea;
        }
        
        .section h2 {
            color: #667eea;
            margin-top: 0;
            margin-bottom: 15px;
        }
        
        input, textarea, button {
            width: 100%;
            padding: 12px;
            margin: 8px 0;
            border: 2px solid #ddd;
            border-radius: 8px;
            font-size: 14px;
            box-sizing: border-box;
        }
        
        input:focus, textarea:focus {
            outline: none;
            border-color: #667eea;
        }
        
        button {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            border: none;
            cursor: pointer;
            font-weight: bold;
            transition: transform 0.2s;
        }
        
        button:hover {
            transform: translateY(-2px);
        }
        
        button:disabled {
            background: #ccc;
            cursor: not-allowed;
            transform: none;
        }
        
        .status {
            padding: 10px;
            margin: 10px 0;
            border-radius: 5px;
            font-weight: 500;
        }
        
        .success {
            background: #d4edda;
            color: #155724;
            border: 1px solid #c3e6cb;
        }
        
        .error {
            background: #f8d7da;
            color: #721c24;
            border: 1px solid #f5c6cb;
        }
        
        .info {
            background: #d1ecf1;
            color: #0c5460;
            border: 1px solid #bee5eb;
        }
        
        .audio-controls {
            display: flex;
            gap: 10px;
            margin-top: 10px;
        }
        
        .audio-controls button {
            flex: 1;
            padding: 10px;
        }
        
        #questionText {
            background: #fff;
            font-size: 16px;
            line-height: 1.6;
            min-height: 60px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üé§ Audio Interview Tester</h1>
        
        <!-- Step 1: Enter Question ID -->
        <div class="section">
            <h2>Step 1: Enter Question ID</h2>
            <input type="text" id="questionId" placeholder="Enter question UUID (e.g., f991c3f8-9ad2-44a0-ad95-4c16d5193b57)" value="f991c3f8-9ad2-44a0-ad95-4c16d5193b57">
            <button onclick="loadQuestion()">Load Question</button>
            <div id="loadStatus"></div>
        </div>
        
        <!-- Step 2: Question Text -->
        <div class="section">
            <h2>Step 2: Question Text</h2>
            <textarea id="questionText" readonly placeholder="Question will appear here..."></textarea>
            
            <!-- AI Audio Info -->
            <div class="section" style="background: #e8f5e9; border-left-color: #4caf50;">
                <h3 style="color: #4caf50;">ü§ñ AI-Generated Audio</h3>
                <p>Click "Play AI Audio" to hear the question spoken by ElevenLabs AI voice, or use browser TTS as fallback.</p>
            </div>
            
            <!-- Audio Controls -->
            <div class="audio-controls">
                <button onclick="speakQuestion()" id="speakBtn" disabled>ü§ñ Play AI Audio</button>
                <button onclick="stopSpeaking()" id="stopBtn" disabled>‚èπÔ∏è Stop</button>
            </div>
        </div>
        
        <!-- Step 3: Record Answer -->
        <div class="section">
            <h2>Step 3: Record Audio Answer</h2>
            <div class="audio-controls">
                <button onclick="startRecording()" id="recordBtn" disabled>üéôÔ∏è Start Recording</button>
                <button onclick="stopRecording()" id="recordingStopBtn" disabled>‚èπÔ∏è Stop & Get Transcription</button>
            </div>
            <div id="recordStatus"></div>
            <textarea id="transcribedText" placeholder="Your transcribed answer will appear here..."></textarea>
        </div>
        
        <!-- Step 4: Submit Answer -->
        <div class="section">
            <h2>Step 4: Submit Answer</h2>
            <input type="text" id="jwtToken" value="eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ0b2tlbl90eXBlIjoiYWNjZXNzIiwiZXhwIjoxNzYxNzY5MDY0LCJpYXQiOjE3NjE3NjU0NjQsImp0aSI6ImM2NmFjNzIzMGNkYjRhM2Q5NTBiNDczZWVkMjAzNGI4IiwidXNlcl9pZCI6MjEsInJvbGUiOiJqb2JzZWVrZXIiLCJ1c2VybmFtZSI6InNlZWtlcjEifQ.8Xq8JgQBZRhPFQV8edU7OQemG1_WJrUEhluZUks1gIA" placeholder="Enter JWT Token (from login)">
            <button onclick="submitAnswer()" id="submitBtn" disabled>üì§ Submit Answer</button>
            <div id="submitStatus"></div>
        </div>
        
        <!-- Step 5: Results -->
        <div class="section">
            <h2>Results</h2>
            <pre id="results"></pre>
        </div>
    </div>

    <script>
        let synth = window.speechSynthesis;
        let recognition = null;
        let audioChunks = [];
        let mediaRecorder = null;
        let questionId = '';
        let questionText = '';
        let audioBlob = null;
        
        // Speech Synthesis Setup
        function initSpeechSynthesis() {
            synth = window.speechSynthesis;
            if (!synth) {
                showStatus('loadStatus', 'Browser does not support text-to-speech', 'error');
                return;
            }
        }
        
        // Speech Recognition Setup
        function initSpeechRecognition() {
            if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
                recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
                recognition.continuous = true;
                recognition.interimResults = true;
                
                recognition.onresult = (event) => {
                    let interimTranscript = '';
                    let finalTranscript = '';
                    
                    for (let i = event.resultIndex; i < event.results.length; i++) {
                        if (event.results[i].isFinal) {
                            finalTranscript += event.results[i][0].transcript + ' ';
                        } else {
                            interimTranscript += event.results[i][0].transcript;
                        }
                    }
                    
                    document.getElementById('transcribedText').value = finalTranscript || interimTranscript;
                };
                
                recognition.onerror = (event) => {
                    showStatus('recordStatus', `Recognition error: ${event.error}`, 'error');
                };
            } else {
                showStatus('recordStatus', 'Speech recognition not supported. Use manual input.', 'info');
            }
        }
        
        // Load question from API
        async function loadQuestion() {
            questionId = document.getElementById('questionId').value.trim();
            
            if (!questionId) {
                showStatus('loadStatus', 'Please enter a question ID', 'error');
                return;
            }
            
            const jwtToken = document.getElementById('jwtToken').value;
            if (!jwtToken) {
                showStatus('loadStatus', 'Please enter JWT token first', 'error');
                return;
            }
            
            try {
                showStatus('loadStatus', 'Loading question...', 'info');
                
                const response = await fetch(`http://localhost:8000/api/audio-interview/question/${questionId}/audio/`, {
                    headers: {
                        'Authorization': `Bearer ${jwtToken}`
                    }
                });
                
                if (!response.ok) {
                    throw new Error(`HTTP ${response.status}`);
                }
                
            const contentType = response.headers.get('content-type');
            
            if (contentType && contentType.includes('audio')) {
                // Server returned audio file (ElevenLabs TTS)
                const audioBlob = await response.blob();
                const audioUrl = URL.createObjectURL(audioBlob);
                const audio = new Audio(audioUrl);
                
                audio.onloadeddata = () => {
                    showStatus('loadStatus', '‚úÖ AI audio loaded! Click Play AI Audio to hear it.', 'success');
                    document.getElementById('speakBtn').disabled = false;
                    document.getElementById('recordBtn').disabled = false;
                    window.currentAudio = audio;
                };
                
                audio.onerror = () => {
                    showStatus('loadStatus', '‚ùå Error loading AI audio', 'error');
                };
                
                // Get question text from the question ID (we'll need to make another request)
                questionText = 'Question loaded with AI audio';
                document.getElementById('questionText').value = questionText;
                
            } else {
                // Server returned JSON (fallback to browser TTS)
                const data = await response.json();
                questionText = data.question_text;
                
                document.getElementById('questionText').value = questionText;
                document.getElementById('speakBtn').disabled = false;
                document.getElementById('recordBtn').disabled = false;
                
                // Store voice settings for TTS
                window.currentVoice = data.voice_id || 'alloy';
                window.currentLanguage = data.language || 'en';
                
                showStatus('loadStatus', '‚úÖ Question loaded! Use browser TTS to hear it.', 'success');
            }
            } catch (error) {
                showStatus('loadStatus', `‚ùå Error loading question: ${error.message}`, 'error');
            }
        }
        
        // Speak question using TTS
        function speakQuestion() {
            if (window.currentAudio) {
                // Play AI-generated audio
                window.currentAudio.play();
                showStatus('loadStatus', 'ü§ñ Playing AI-generated audio...', 'info');
                
                window.currentAudio.onended = () => {
                    showStatus('loadStatus', '‚úÖ AI audio finished playing', 'success');
                };
                
                window.currentAudio.onerror = () => {
                    showStatus('loadStatus', '‚ùå Error playing AI audio', 'error');
                };
                
            } else if (questionText) {
                // Use browser TTS as fallback
                synth.cancel(); // Stop any ongoing speech
                
                const utterance = new SpeechSynthesisUtterance(questionText);
                utterance.rate = 0.9; // Slightly slower for interview questions
                utterance.pitch = 1.0;
                utterance.volume = 1.0;
                utterance.lang = window.currentLanguage || 'en-US';
                
                // Try to set voice if available
                const voices = synth.getVoices();
                const preferredVoice = voices.find(voice => 
                    voice.name.toLowerCase().includes('alloy') || 
                    voice.name.toLowerCase().includes('female') ||
                    voice.name.toLowerCase().includes('woman')
                );
                if (preferredVoice) {
                    utterance.voice = preferredVoice;
                }
                
                utterance.onstart = () => {
                    document.getElementById('speakBtn').disabled = true;
                    document.getElementById('stopBtn').disabled = false;
                    showStatus('loadStatus', 'üîä Speaking question with browser TTS...', 'info');
                };
                
                utterance.onend = () => {
                    document.getElementById('speakBtn').disabled = false;
                    document.getElementById('stopBtn').disabled = true;
                    showStatus('loadStatus', '‚úÖ Question finished speaking', 'success');
                };
                
                synth.speak(utterance);
            } else {
                showStatus('loadStatus', 'No question loaded', 'error');
            }
        }
        
        // Stop speaking
        function stopSpeaking() {
            if (window.currentAudio) {
                // Stop AI audio
                window.currentAudio.pause();
                window.currentAudio.currentTime = 0;
            } else {
                // Stop browser TTS
                synth.cancel();
            }
            document.getElementById('speakBtn').disabled = false;
            document.getElementById('stopBtn').disabled = true;
        }
        
        
        // Start recording audio
        async function startRecording() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                
                mediaRecorder = new MediaRecorder(stream);
                audioChunks = [];
                
                mediaRecorder.ondataavailable = (event) => {
                    audioChunks.push(event.data);
                };
                
                mediaRecorder.onstop = () => {
                    audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                };
                
                mediaRecorder.start();
                
                document.getElementById('recordBtn').disabled = true;
                document.getElementById('recordingStopBtn').disabled = false;
                showStatus('recordStatus', 'üéôÔ∏è Recording... (click Stop when done)', 'info');
                
                // Also start voice recognition for live transcription
                if (recognition) {
                    recognition.start();
                    showStatus('recordStatus', 'üéôÔ∏è Recording with live transcription...', 'info');
                }
            } catch (error) {
                showStatus('recordStatus', `‚ùå Error: ${error.message}`, 'error');
            }
        }
        
        // Stop recording
        function stopRecording() {
            if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                mediaRecorder.stop();
                
                // Stop all tracks
                mediaRecorder.stream.getTracks().forEach(track => track.stop());
                
                document.getElementById('recordBtn').disabled = false;
                document.getElementById('recordingStopBtn').disabled = true;
                showStatus('recordStatus', '‚úÖ Recording stopped', 'success');
            }
            
            if (recognition) {
                recognition.stop();
            }
            
            // Enable submit if we have audio and text
            const transcribedText = document.getElementById('transcribedText').value;
            if (audioBlob && transcribedText) {
                document.getElementById('submitBtn').disabled = false;
            }
        }
        
        // Submit answer to API
        async function submitAnswer() {
            const jwtToken = document.getElementById('jwtToken').value;
            const transcribedText = document.getElementById('transcribedText').value;
            
            if (!audioBlob) {
                showStatus('submitStatus', 'No audio recorded', 'error');
                return;
            }
            
            try {
                showStatus('submitStatus', 'Submitting answer...', 'info');
                
                const formData = new FormData();
                formData.append('question_id', questionId);
                formData.append('audio_file', audioBlob, 'answer.webm');
                formData.append('transcribed_text', transcribedText);
                formData.append('transcription_confidence', '0.9');
                
                const response = await fetch('http://localhost:8000/api/audio-interview/submit-answer/', {
                    method: 'POST',
                    headers: {
                        'Authorization': `Bearer ${jwtToken}`
                    },
                    body: formData
                });
                
                if (!response.ok) {
                    const error = await response.text();
                    throw new Error(error);
                }
                
                const data = await response.json();
                showStatus('submitStatus', '‚úÖ Answer submitted successfully!', 'success');
                
                document.getElementById('results').textContent = JSON.stringify(data, null, 2);
                
                // Reset for next question
                document.getElementById('submitBtn').disabled = true;
                
            } catch (error) {
                showStatus('submitStatus', `‚ùå Error: ${error.message}`, 'error');
            }
        }
        
        // Helper function to show status
        function showStatus(elementId, message, type) {
            const element = document.getElementById(elementId);
            element.textContent = message;
            element.className = `status ${type}`;
            
            setTimeout(() => {
                element.textContent = '';
                element.className = '';
            }, 5000);
        }
        
        // Initialize on page load
        window.onload = () => {
            initSpeechSynthesis();
            initSpeechRecognition();
            console.log('üé§ Audio Interview Tester Ready!');
        };
    </script>
</body>
</html>
